<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>吴恩达-机器学习-线性回归模型(包括梯度下降)</title>
    <link href="/2022/11/25/%E5%90%B4%E6%81%A9%E8%BE%BE-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/11/25/%E5%90%B4%E6%81%A9%E8%BE%BE-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>对于线性模型</p><script type="math/tex; mode=display">f(x)=wx+b</script><p>来说w,b称为模型的参数(parameters,也可以称为coefficients,weights)</p><p>对于w,b来说我们的目标是如何让对于所有的训练集$(x^{(i)},y^{(i)})$来说让$\hat y^{(i)}$与$y^{(i)}$最小</p><p><img src="/2022/11/25/%E5%90%B4%E6%81%A9%E8%BE%BE-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/Snipaste_2022-11-25_21-35-47.png" alt></p><p>所以它的代价函数(cost function)也十分简单:</p><script type="math/tex; mode=display">J(w,b)=\frac{1}{2m}\sum\limits_{i=1}^m{(\hat y^{(i)}-\hat y ^{(i)})^2}</script><p>这里的2是未来方便运算，分母的m是确保随着训练集样本数量的变大，代价函数的值不会随之增大</p><h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>在获得损失函数J(w,b)之后，我们希望当J(w,b)取最小值时的的参数w,b的值，可以通过梯度下降来实现</p><script type="math/tex; mode=display">w=w-\alpha \frac{\partial}{\partial w} J(w, b)</script><script type="math/tex; mode=display">b=b-\alpha \frac{\partial}{\partial b} J(w, b)</script><p>其中$\alpha$ 是学习率$\frac{\partial}{\partial w} J(w, b)$ 是J(w,b)对w的偏导，$\frac {\partial}{\partial b} J(w, b)$ 是J(w,b)对b的偏导。</p><p>显然,$\alpha$ 如果很小，那么梯度下降可能会非常慢(收敛很慢)。如果$\alpha$ 非常大,可能导致过冲(overshoot)，震荡，甚至永远不会到达最小值，甚至可能发散。</p><p><img src="/2022/11/25/%E5%90%B4%E6%81%A9%E8%BE%BE-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/Snipaste_2022-11-29_16-23-09.png" alt></p><p>但是固定的学习率$\alpha$ 能让损失函数到达局部最小值，因为随着到达局部最小值，导数的值会变小趋近于0，这意味这更新步骤也会越边越小。</p><p><img src="/2022/11/25/%E5%90%B4%E6%81%A9%E8%BE%BE-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/Snipaste_2022-11-29_16-35-12.png" alt></p><p>对于线性回归的模型来说，梯度下降为</p><script type="math/tex; mode=display">w=w-\alpha \frac{1}{m} \sum_{i=1}\left(f_{w, b}(x^{(i)})-y^{(i)}\right) x^{(i)}</script><script type="math/tex; mode=display">b=b-\alpha \frac{1}{m} \sum_{i=1}^m\left(f_{w, b}(x^{(i)})-y^{(i)}\right)</script><p>同时线性模型的损失函数是一个凸函数(convex function)，除了全局最小值，它没有任何局部最小值</p><p><img src="/2022/11/25/%E5%90%B4%E6%81%A9%E8%BE%BE-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/Snipaste_2022-11-29_16-55-20.png" alt></p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>监督学习</title>
    <link href="/2022/11/24/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <url>/2022/11/24/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># %%</span><br><span class="hljs-keyword">import</span> sklearn <span class="hljs-keyword">as</span> sk<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> fetch_olivetti_faces<br>faces=fetch_olivetti_faces()<br><span class="hljs-comment"># print(faces.DESCR)</span><br><br><span class="hljs-comment"># %%</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_faces</span>(<span class="hljs-params">images,target,top_n</span>):<br>    fig =plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">12</span>))<span class="hljs-comment">#创造一个画板</span><br>    fig.subplots_adjust(left=<span class="hljs-number">0</span>,right=<span class="hljs-number">1</span>,bottom=<span class="hljs-number">0</span>,top=<span class="hljs-number">1</span>,hspace=<span class="hljs-number">0.05</span>,wspace=<span class="hljs-number">0.05</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(top_n):<br>        p=fig.add_subplot(<span class="hljs-number">20</span>,<span class="hljs-number">20</span>,i+<span class="hljs-number">1</span>,xticks=[],yticks=[])<br>        p.imshow(images[i],cmap=plt.cm.bone)<br>        p.text(<span class="hljs-number">0</span>,<span class="hljs-number">14</span>,<span class="hljs-built_in">str</span>(target[i]))<br>        p.text(<span class="hljs-number">0</span>,<span class="hljs-number">60</span>,<span class="hljs-built_in">str</span>(i))<br>print_faces(faces.images,faces.target,<span class="hljs-number">20</span>)<br><br><span class="hljs-comment"># %%</span><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_and_evaluate</span>(<span class="hljs-params">clf,X_train,X_test,Y_train,Y_test</span>):<br>    clf.fit(X_train,Y_train)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy on training set:&quot;</span>)<br>    <span class="hljs-built_in">print</span>(clf.score(X_train,Y_train))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy on testing set&quot;</span>)<br>    <span class="hljs-built_in">print</span>(clf.score(X_test,Y_test))<br><br>    Y_pred=clf.predict(X_test)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Classification Report:&quot;</span>)<br>    <span class="hljs-built_in">print</span>(metrics.classification_report(Y_test,Y_pred))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Confusion Matrix&quot;</span>)<br>    <span class="hljs-built_in">print</span>(metrics.confusion_matrix(Y_test,Y_pred))<br><br><span class="hljs-comment"># %%</span><br><span class="hljs-comment">#定义函数来评估K交叉验证</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score,KFold<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> sem<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_cross_validation</span>(<span class="hljs-params">clf,X,Y,K</span>):<br>    cv=KFold(K,shuffle=<span class="hljs-literal">True</span>,random_state=<span class="hljs-number">0</span>)<br>    scores=cross_val_score(clf,X,Y,cv=cv)<br>    <span class="hljs-built_in">print</span>(scores)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Mean score: &#123;0:.3f&#125; (+/-&#123;1:.3f&#125;)&quot;</span>.<span class="hljs-built_in">format</span>(np.mean(scores),sem(scores)))<br><br><br><span class="hljs-comment"># %%</span><br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC <br><span class="hljs-keyword">from</span>   sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br><span class="hljs-comment"># the index ranges of images of people with glasses</span><br>glasses = [<br>   (<span class="hljs-number">10</span>, <span class="hljs-number">19</span>), (<span class="hljs-number">30</span>, <span class="hljs-number">32</span>), (<span class="hljs-number">37</span>, <span class="hljs-number">38</span>), (<span class="hljs-number">50</span>, <span class="hljs-number">59</span>), (<span class="hljs-number">63</span>, <span class="hljs-number">64</span>),<br>   (<span class="hljs-number">69</span>, <span class="hljs-number">69</span>), (<span class="hljs-number">120</span>, <span class="hljs-number">121</span>), (<span class="hljs-number">124</span>, <span class="hljs-number">129</span>), (<span class="hljs-number">130</span>, <span class="hljs-number">139</span>), (<span class="hljs-number">160</span>, <span class="hljs-number">161</span>),<br>   (<span class="hljs-number">164</span>, <span class="hljs-number">169</span>), (<span class="hljs-number">180</span>, <span class="hljs-number">182</span>), (<span class="hljs-number">185</span>, <span class="hljs-number">185</span>), (<span class="hljs-number">189</span>, <span class="hljs-number">189</span>), (<span class="hljs-number">190</span>, <span class="hljs-number">192</span>),<br>   (<span class="hljs-number">194</span>, <span class="hljs-number">194</span>), (<span class="hljs-number">196</span>, <span class="hljs-number">199</span>), (<span class="hljs-number">260</span>, <span class="hljs-number">269</span>), (<span class="hljs-number">270</span>, <span class="hljs-number">279</span>), (<span class="hljs-number">300</span>, <span class="hljs-number">309</span>),<br>   (<span class="hljs-number">330</span>, <span class="hljs-number">339</span>), (<span class="hljs-number">358</span>, <span class="hljs-number">359</span>), (<span class="hljs-number">360</span>, <span class="hljs-number">369</span>)<br>]<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_targe</span>(<span class="hljs-params">segments</span>):<br>    y=np.zeros(faces.target.shape[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">for</span> (start,end) <span class="hljs-keyword">in</span> segments:<br>        y[start:end+<span class="hljs-number">1</span>]=<span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> y<br>target_glasses=create_targe(glasses)<br>X_train,X_test,Y_train,Y_test=train_test_split(faces.data,target_glasses,test_size=<span class="hljs-number">0.25</span>,random_state=<span class="hljs-number">0</span>)<br>svc_2=SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>)<br><br><br><span class="hljs-comment"># %%</span><br>evaluate_cross_validation(svc_2,X_train,Y_train,<span class="hljs-number">5</span>)<br>train_and_evaluate(svc_2,X_train,X_test,Y_train,Y_test)<br><br><span class="hljs-comment"># %%</span><br>X_test = faces.data[<span class="hljs-number">30</span>:<span class="hljs-number">40</span>]<br>Y_test= target_glasses[<span class="hljs-number">30</span>:<span class="hljs-number">40</span>]<br><span class="hljs-built_in">print</span>(Y_test.shape[<span class="hljs-number">0</span>])<br>select = np.ones(target_glasses.shape[<span class="hljs-number">0</span>])<br>X_train = faces.data[select ==  <span class="hljs-number">1</span>]<br>Y_train = target_glasses[select ==  <span class="hljs-number">1</span>]<br>svc_3=SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>)<br>train_and_evaluate(svc_3,X_train,X_test,Y_train,Y_test)<br><br><br><br><span class="hljs-comment"># %%</span><br>Y_pred=svc_3.predict(X_test)<br>eval_faces=[np.reshape(a,(<span class="hljs-number">64</span>,<span class="hljs-number">64</span>)) <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> X_test]<br>print_faces(eval_faces,Y_pred,<span class="hljs-number">10</span>)<br><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>机器学习-温和的介绍</title>
    <link href="/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B8%A9%E5%92%8C%E7%9A%84%E4%BB%8B%E7%BB%8D/"/>
    <url>/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B8%A9%E5%92%8C%E7%9A%84%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="机器学习概念"><a href="#机器学习概念" class="headerlink" title="机器学习概念"></a>机器学习概念</h1><p>任何机器学习都可以通过以下三个概念表示:</p><p>任务T：比如构建一个垃圾邮件过滤器，将电子邮件归类为垃圾邮件或正常邮件。</p><p>经验E：通过经验来学习执行任务。比如对于垃圾邮件过滤器，需要将一组电子邮件人工分类为电子邮件或正常邮件。</p><p>表现P:来体现表现任务的能力，比如我们的垃圾邮件过滤器将电子邮件正确分类为垃圾邮件或正常邮件的百分比。</p><h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>机器学习方法依赖于以前的经验，通常由数据集表示。这里使用鸢尾花数据集，它包含来自三种不同鸢尾花物种的150个实例，包括萼片和花瓣的长度和宽度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><br>iris = datasets.load_iris()<br>X_iris, Y_iris = iris.data, iris.target<br><span class="hljs-built_in">print</span>(X_iris.shape, Y_iris.shape)<span class="hljs-comment"># (150, 4) (150,)</span><br><span class="hljs-built_in">print</span>(X_iris[<span class="hljs-number">0</span>], Y_iris[<span class="hljs-number">0</span>]) <span class="hljs-comment"># [5.1 3.5 1.4 0.2] 0</span><br></code></pre></td></tr></table></figure><p><strong>iris</strong>数据集是一个对象，它有两个主要部分:</p><p>一个<strong>data</strong>数组，对于每个实例，都有萼片长度，萼片宽度，花瓣长度，花瓣宽度。（scikit-learn使用ndarrays,而不是更具描述性但效率更低的Python词典或列表。这个数组的shape是(150,4)，代表有150行实例和每个实例4个特征</p><p>一个<strong>targe</strong>数组，值在0到2的范围，分别对应(0:山鸢尾，1:杂色鸢尾，2:弗吉尼亚鸢尾)</p><h1 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h1><p>线性分类模型试图做的:构建一条线(或者说特征空间的超平面)，最优的分离两个目标类，并将其用作决策边界</p><p>这里引入一个简单的学习任务：我们瞄准鸢尾花实例，以预测它是否是一个山鸢尾。这是一个二元分类任务。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>iris = datasets.load_iris()<br>X_iris, Y_iris = iris.data, iris.target<br>X, Y = X_iris[:, :<span class="hljs-number">2</span>], Y_iris<br>X_train, X_test, Y_train, Y_test = train_test_split(<br>    X, Y, test_size=<span class="hljs-number">0.25</span>, random_state=<span class="hljs-number">33</span>)<br><br>scaler = preprocessing.StandardScaler().fit(X_train)<br>X_train = scaler.transform(X_train)<br>X_test = scaler.transform(X_test)<br><br>colors = [<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(colors)):<br>    xs = X_train[:, <span class="hljs-number">0</span>][Y_train == i]<br>    ys = X_train[:, <span class="hljs-number">1</span>][Y_train == i]<br>    plt.scatter(xs, ys, c=colors[i])<br><br>plt.legend(iris.target_names)<br>plt.xlabel(<span class="hljs-string">&#x27;Sepal length&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Sepal width&#x27;</span>)<br>plt.show()<br><br></code></pre></td></tr></table></figure><p><img src="/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B8%A9%E5%92%8C%E7%9A%84%E4%BB%8B%E7%BB%8D/Figure_1.png" alt="Figure_1"></p><p>实现线性分类，需要使用scikit-learn中的SGDClassfuer,SGD代表随机梯度下降，用于查找函数的局部最小值（本例中为损失函数），fit函数接受训练数据和训练类别，并且构造分类器。现在根据clf的属性有</p><script type="math/tex; mode=display">clf.intercept_[i]+x1*clf.coef_[i,0]+clf.coef[i,1]*x2=0</script><p>即给定x1和x2的值，如果它的值大于0，它就在决策边界之上。但是系数矩阵有三行，代表它提出了三个将一个类与其他类别分开的直线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> s了klearn <span class="hljs-keyword">import</span> preprocessing<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>iris = datasets.load_iris()<br>X_iris, Y_iris = iris.data, iris.target<br>X, Y = X_iris[:, :<span class="hljs-number">2</span>], Y_iris<br>X_train, X_test, Y_train, Y_test = train_test_split(<br>    X, Y, test_size=<span class="hljs-number">0.25</span>, random_state=<span class="hljs-number">33</span>)<br><br>scaler = preprocessing.StandardScaler().fit(X_train)<br>X_train = scaler.transform(X_train)<br>X_test = scaler.transform(X_test)<br><br><span class="hljs-comment"># colors = [&#x27;red&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;]</span><br><span class="hljs-comment"># for i in range(len(colors)):</span><br><span class="hljs-comment">#     xs = X_train[:, 0][Y_train == i]</span><br><span class="hljs-comment">#     ys = X_train[:, 1][Y_train == i]</span><br><span class="hljs-comment">#     plt.scatter(xs, ys, c=colors[i])</span><br><br><span class="hljs-comment"># plt.legend(iris.target_names)</span><br><span class="hljs-comment"># plt.xlabel(&#x27;Sepal length&#x27;)</span><br><span class="hljs-comment"># plt.ylabel(&#x27;Sepal width&#x27;)</span><br><span class="hljs-comment"># plt.show()</span><br><br>clf=SGDClassifier()<br>clf.fit(X_train,Y_train)<br>Y_train_pred=clf.predict(X_train)<br><span class="hljs-comment"># print(metrics.accuracy_score(Y_train,Y_train_pred))</span><br><span class="hljs-comment"># print(clf.coef_)</span><br><br>x_min,x_max=X_train[:,<span class="hljs-number">0</span>].<span class="hljs-built_in">min</span>()-<span class="hljs-number">.5</span>,X_train[:,<span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>()+<span class="hljs-number">.5</span><br>y_min,y_max=X_train[:,<span class="hljs-number">1</span>].<span class="hljs-built_in">min</span>()-<span class="hljs-number">.5</span>,X_train[:,<span class="hljs-number">1</span>].<span class="hljs-built_in">max</span>()+<span class="hljs-number">.5</span><br>xs=np.arange(x_min,x_max,<span class="hljs-number">0.5</span>)<br>fig,axes=plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br>fig.set_size_inches(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>    axes[i].set_aspect(<span class="hljs-string">&#x27;equal&#x27;</span>)<br>    axes[i].set_title(<span class="hljs-built_in">str</span>(i))<br>    axes[i].set_xlabel(<span class="hljs-string">&#x27;length&#x27;</span>)<br>    axes[i].set_ylabel(<span class="hljs-string">&#x27;width&#x27;</span>)<br>    axes[i].set_xlim(x_min,x_max)<br>    axes[i].set_ylim(y_min,y_max)<br>    plt.sca(axes[i])<br>    plt.scatter(X_train[:,<span class="hljs-number">0</span>],X_train[:,<span class="hljs-number">1</span>],c=Y_train,cmap=plt.cm.prism)<br>    ys=(-clf.intercept_[i]-xs*clf.coef_[i,<span class="hljs-number">0</span>])/clf.coef_[i,<span class="hljs-number">1</span>]<span class="hljs-comment">#clf.intercept_[i]+xs*clf.coef_[i,0]+clf.coef[i,1]*ys=0</span><br>    plt.plot(xs,ys)<br>    <br><br>plt.show()<br><br></code></pre></td></tr></table></figure><p><img src="/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B8%A9%E5%92%8C%E7%9A%84%E4%BB%8B%E7%BB%8D/res.png" alt="res"></p><h1 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h1><div class="table-container"><table><thead><tr><th></th><th>预测：正例</th><th>预测:负例</th></tr></thead><tbody><tr><td>目标:正例</td><td>真正例(TP)</td><td>假负例(FN)</td></tr><tr><td>目标:负例</td><td>假正例(FP)</td><td>真负例(TN)</td></tr></tbody></table></div><p>m为样本量即m=TP+TN+FP+FB</p><p>准确率=(TP+TN)/m</p><p>精确率= TP /（TP+FP）</p><p>召回率=TP /   (TP+FN)</p><p>F1 得分 =2  <em> 精确率  </em> 召回 / （精确率 + 召回率)</p><p>sklearn中可以如下所用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>iris = datasets.load_iris()<br>X_iris, Y_iris = iris.data, iris.target<br>X, Y = X_iris[:, :<span class="hljs-number">2</span>], Y_iris<br>X_train, X_test, Y_train, Y_test = train_test_split(<br>    X, Y, test_size=<span class="hljs-number">0.25</span>, random_state=<span class="hljs-number">33</span>)<br><br>scaler = preprocessing.StandardScaler().fit(X_train)<br>X_train = scaler.transform(X_train)<br>X_test = scaler.transform(X_test)<br><br><br><br>clf=SGDClassifier()<br>clf.fit(X_train,Y_train)<br>Y_pred=clf.predict(X_test)<br><span class="hljs-built_in">print</span>(metrics.classification_report(Y_test,Y_pred,target_names=iris.target_names))<br><br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs ini">precision    recall  f1-score   support<br><br>      setosa       1.00      1.00      1.00         8<br>  versicolor       0.00      0.00      0.00        11<br>   virginica       0.63      1.00      0.78        19<br><br>    accuracy                           0.71        38<br>   macro avg       0.54      0.67      0.59        38<br>weighted avg       0.53      0.71      0.60        38<br></code></pre></td></tr></table></figure><p>此外，对于评估过程，我们可以使用交叉验证。K折交叉验证的常用步骤如下:</p><ol><li>将数据集划分为K个不同子集</li><li>通过训练k-1个子集并测试剩余的一个子集来创建k个不同模型</li><li>测量k个模型的表现并取平均值</li></ol><p>比如k=5就代表每次训练80%数据并测试剩余20%</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">*<span class="hljs-keyword">from</span>* sklearn.model_selection *<span class="hljs-keyword">import</span>* cross_val_score, KFold<br><br>*<span class="hljs-keyword">from</span>* sklearn.pipeline *<span class="hljs-keyword">import</span>* Pipeline<br><br>*<span class="hljs-keyword">from</span>* sklearn.linear_model *<span class="hljs-keyword">import</span>* SGDClassifier<br><br>*<span class="hljs-keyword">from</span>* sklearn *<span class="hljs-keyword">import</span>* datasets<br><br>*<span class="hljs-keyword">from</span>* sklearn *<span class="hljs-keyword">import</span>* preprocessing<br><br><br><br>iris = datasets.load_iris()<br><br>X_iris, Y_iris = iris.data, iris.target<br><br>X, Y = X_iris[:, :<span class="hljs-number">2</span>], Y_iris<br><br>clf = Pipeline([<br><br>  (<span class="hljs-string">&#x27;scaler&#x27;</span>, preprocessing.StandardScaler()),<br><br>  (<span class="hljs-string">&#x27;linear_model&#x27;</span>, SGDClassifier())<br><br>])<br><br><br><br>cv = KFold(<span class="hljs-number">5</span>, *shuffle*=<span class="hljs-literal">True</span>, *random_state*=<span class="hljs-number">22</span>)<br><br>score = cross_val_score(clf, X, Y, *cv*=cv)<br><br><span class="hljs-built_in">print</span>(score)<span class="hljs-comment"># [0.76666667 0.76666667 0.86666667 0.73333333 0.7       ]</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>sylar服务器框架</title>
    <link href="/2022/11/05/sylar%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A1%86%E6%9E%B6/"/>
    <url>/2022/11/05/sylar%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="sylar"><a href="#sylar" class="headerlink" title="sylar"></a>sylar</h1><h2 id="日志系统"><a href="#日志系统" class="headerlink" title="日志系统"></a>日志系统</h2><p>1)<br>    Log4j</p><pre><code class="hljs">Logger(定义日志类别)  |  |---------Formatter(日志格式)  |Appender(日志输出地方)</code></pre><h2 id="协程库封装"><a href="#协程库封装" class="headerlink" title="协程库封装"></a>协程库封装</h2><h2 id="socket函数库"><a href="#socket函数库" class="headerlink" title="socket函数库"></a>socket函数库</h2><h2 id="http协议开发"><a href="#http协议开发" class="headerlink" title="http协议开发"></a>http协议开发</h2><h2 id="分布协议"><a href="#分布协议" class="headerlink" title="分布协议"></a>分布协议</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>测试</title>
    <link href="/2022/11/05/%E6%B5%8B%E8%AF%95/"/>
    <url>/2022/11/05/%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<p>测试一下</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
